{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch as torch\n",
    "import pandas as pd\n",
    "import pickle as pickle\n",
    "import random\n",
    "import faiss\n",
    "from nltk.tokenize import sent_tokenize\n",
    "import keras\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "user_asp=pd.read_pickle('用户训练集aspect合集')\n",
    "temp=set()\n",
    "for i in range(len(user_asp)):\n",
    "    for j in range(len(user_asp[i])):\n",
    "        tempppp.add(user_asp[i][j])\n",
    "len(temp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tempa=[]\n",
    "tempb=[]\n",
    "count=0\n",
    "file_a=open('../generated.txt')\n",
    "for line in file_a.readlines():\n",
    "    count=count+1\n",
    "    if count%4==1:\n",
    "        tempa.append(line.strip().split())\n",
    "    elif count%4==3:\n",
    "        tempb.append(line.strip().split())\n",
    "    else:\n",
    "        continue;\n",
    "file_a.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "count=0\n",
    "dicfile=open('vocab.txt')\n",
    "file1 = dicfile.read()\n",
    "aspect=open('vocab_total_aspect.txt','r')   \n",
    "# new_file=open('new_total_aspect.txt','w+')\n",
    "lines = aspect.readlines()\n",
    "for line in lines:\n",
    "    if count%10000==0:\n",
    "        count=count+1\n",
    "        print(count)\n",
    "    temp=line.split()\n",
    "    for i in range(len(temp)):\n",
    "        if 'dden'+'\\n' in file1:\n",
    "            print(11)\n",
    "            continue;  \n",
    "        else: \n",
    "            print(temp[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ans_voacb=[]\n",
    "dicfile=open('vocab.txt')\n",
    "file1 = dicfile.readlines()\n",
    "for line in file1:\n",
    "#     if count%1000==0:\n",
    "#         count=count+1\n",
    "#         print(count)\n",
    "    ans_voacb.append(line)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "aspect=open('True_label.txt','r')   \n",
    "new_file=open('zhen_True_label.txt','w+')\n",
    "lines = aspect.readlines()\n",
    "for line in lines:\n",
    "    temp=line.split()\n",
    "    for i in range(len(temp)):\n",
    "        if temp[i]+'\\n' in ans_voacb:\n",
    "            new_file.writelines(temp[i]+' ')\n",
    "        else: \n",
    "            new_file.writelines('')\n",
    "    new_file.writelines('\\n')\n",
    "new_file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dicfile=open('vocab.txt')\n",
    "file1 = dicfile.read()\n",
    "aspect=open('pinjie_total_aspect.txt','r')   \n",
    "new_file=open('new_total_aspect.txt','w+')\n",
    "lines = aspect.readlines()\n",
    "for line in lines:\n",
    "    temp=line.split()\n",
    "    for i in range(len(temp)):\n",
    "        if temp[i] in file1: \n",
    "            new_file.write(temp[i])\n",
    "            print('true') \n",
    "        else: \n",
    "            s.replace(temp[i], '')\n",
    "            f.write(s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test=pd.read_json('./data/train-data/test_df.json')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for index,value in test.iterrows():\n",
    "#     temp=json.loads(value['aspect'])\n",
    "    user={}\n",
    "    temp=eval(value['aspect'])\n",
    "    temp=temp['aspects']\n",
    "    print(temp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "uuu=[]       \n",
    "for i in range(len(temp)):\n",
    "    user_aspect_emb=user_aspect[i][:2]\n",
    "    user_aspect_emb=[' '.join(user_aspect_emb)]\n",
    "    uuu.append(user_aspect_emb)\n",
    "uuu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "item_ff={}\n",
    "for i in range(len(user_aspect[0])):\n",
    "    if 0 in item_ff: #如果存在就直接append\n",
    "        item_ff[0].extend(user_aspect[0][i])\n",
    "    else: #不存在，重新创建一个list\n",
    "        item_ff[0]=user_aspect[0][i]\n",
    "print(item_ff[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import collections"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "user_ff={}\n",
    "user_aspect_ans={}\n",
    "count=0\n",
    "for i in range(len(user_aspect)):\n",
    "    if len(user_aspect[i])==0:\n",
    "        user_ff[i]=user_aspect[i]\n",
    "        continue;\n",
    "    for j in range(len(user_aspect[i])):\n",
    "        if i in user_ff: #如果存在就直接append\n",
    "            user_ff[i].extend(user_aspect[i][j])\n",
    "        else: #不存在，重新创建一个list\n",
    "            user_ff[i]=user_aspect[i][j]      \n",
    "    counter = collections.Counter(user_ff[i])\n",
    "    features_sorted = sorted(counter.items(),key=lambda x:x[1],reverse=True)\n",
    "    features = []\n",
    "    for feature in features_sorted:\n",
    "        features.append(feature[0])\n",
    "    user_aspect_ans[i]=features\n",
    "    count=count+1;\n",
    "    if count%1000==0:\n",
    "        print(count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('./data/train-data/item_aspect.pkl', \"wb\") as fOut:\n",
    "        pickle.dump(user_aspect_ans, fOut)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "item_aspectaaa=pd.read_pickle('./data/train-data/item_aspect.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "torch.load('./model.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sentence_transformers import SentenceTransformer\n",
    "model = SentenceTransformer('paraphrase-MiniLM-L6-v2').to(\"cuda\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "str1=\"why is it bad?\\n Overall a good drink but wouldn't call it amazing. The waiter was nice and food came out quite fast. The chimichanga looked smaller than I'm used to but was very filling! It is a nicer restaurant on the more expensive side so something to keep in mind.. but such good flavor still a 5 star!\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sparse_softmax_cross_entropy_with_logits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "tokenizer.decode(outputs.last_hidden_state[:,-1,:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sss=np.load('./Trip_sve.npy',allow_pickle=True)\n",
    "user_sgl = torch.tensor(sss.item()['user'][user.cpu().numpy()]).to(device)\n",
    "item_sgl = torch.tensor(sss.item()['item'][item.cpu().numpy()]).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model2=model.h"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sentence_transformers import SentenceTransformer\n",
    "model = SentenceTransformer('paraphrase-MiniLM-L6-v2').to(\"cuda\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tot=pd.read_pickle('./data/TripAdvisor/reviews.pickle')\n",
    "tot=pd.DataFrame(tot)\n",
    "tot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "aspect=[]\n",
    "for i,index in tot.iterrows():\n",
    "        aspect.append(index['template'][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(aspect)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "totals=pd.read_json('./data/TripAdvisor/Trip_df.json')\n",
    "totals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "totals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "user_aspect=pd.read_pickle('./ReXPlug-master/data/TripAdvisor/user_aspect.pkl')\n",
    "item_aspect=pd.read_pickle('./ReXPlug-master/data/TripAdvisor/item_aspect.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "user_aspect"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ss=[]\n",
    "for i in range(len(user_aspect)):\n",
    "    if(len(user_aspect[i])==3):\n",
    "        print(user_aspect[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('user_aspect_top2.pkl', 'wb') as f:\n",
    "    pickle.dump(plain_user_reviews_dict, f, pickle.HIGHEST_PROTOCOL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(ss, 'user_aspect_top2.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = torch.load('user_aspect_top2.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(y)):\n",
    "    print(y[i].spilt())\n",
    "    if len(y[i].spilt())==1:\n",
    "        print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "total=pd.read_json('./data/TripAdvisor/train_df.json')\n",
    "total.reset_index(inplace=True, drop=True)\n",
    "total"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i,index in total.iterrows():\n",
    "    if i%10000==0:\n",
    "        print(i)\n",
    "    if type(index['review'])==float:\n",
    "        print(index),print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "review=[]\n",
    "for i,value in total.iterrows():\n",
    "    review.append(value['template'][2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "total['template']=review"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "total = total[['user', 'item', 'template', 'rating']]\n",
    "total.columns = ['userId', 'itemId', 'review', 'rating']\n",
    "total"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "total[\"userId\"] = pd.factorize(total[\"userId\"])[0].astype(int)\n",
    "total[\"itemId\"] = pd.factorize(total[\"itemId\"])[0].astype(int)\n",
    "total.reset_index(inplace=True, drop=True)\n",
    "total"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "total.to_json('./data/yelp2019/Trip_df.json')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#创建user_toitem列表\n",
    "user_toitem={}\n",
    "for i,value in total.iterrows():\n",
    "    if i%50000==0:\n",
    "        print(i)\n",
    "    if value['userId'] not in user_toitem.keys():\n",
    "        user_toitem[value['userId']]=[]\n",
    "        user_toitem[value['userId']].append(value['itemId'])\n",
    "    else:\n",
    "        user_toitem[value['userId']].append(value['itemId'])\n",
    "item_touser={}\n",
    "for i,value in total.iterrows():\n",
    "    if i%50000==0:\n",
    "        print(i)\n",
    "    if value['itemId'] not in item_touser.keys():\n",
    "        item_touser[value['itemId']]=[]\n",
    "        item_touser[value['itemId']].append(value['userId'])\n",
    "    else:\n",
    "        item_touser[value['itemId']].append(value['userId'])\n",
    "torch.save(user_toitem,'./data/yelp2019/user_toitem.pt')\n",
    "torch.save(item_touser,'./data/yelp2019/item_touser.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#对user所有的评论，分句后建模索引\n",
    "user_index_contrust={}\n",
    "user_index_sent={}\n",
    "for i in range(len(user_aspect)):\n",
    "    if i%500==0:\n",
    "        print(i)\n",
    "    temp_u=[]\n",
    "    for j in range(len(user_aspect[i])):\n",
    "#         sents_u = sent_tokenize(user_revs[i][j])\n",
    "        temp_u.append(user_aspect[i][j])\n",
    "#         temp_u.append(user_revs[i][j])\n",
    "#     print(temp_u)\n",
    "    tttt=model.encode(user_aspect[i])\n",
    "    user_index_sent[i]=temp_u\n",
    "    user_index_contrust[i]=tttt\n",
    "with open('./data/TripAdvisor/user_aspect.pkl', \"wb\") as fOut:\n",
    "        pickle.dump({'sentences': user_index_sent, 'embeddings': user_index_contrust}, fOut)\n",
    "#对item所有的评论，分句后建模索引\n",
    "# item_index_contrust={}\n",
    "# item_index_sent={}\n",
    "# for i in range(len(item_revs)):\n",
    "#     if i%1000==0:\n",
    "#         print(i)\n",
    "#     temp_u=[]\n",
    "#     for j in range(len(item_revs[i])):\n",
    "#         sents_u = sent_tokenize(item_revs[i][j])\n",
    "#         temp_u.extend(sents_u)\n",
    "# #         temp_u.append(item_revs[i][j])\n",
    "#     tttt=model.encode(temp_u)\n",
    "#     item_index_sent[i]=temp_u\n",
    "#     item_index_contrust[i]=tttt\n",
    "# with open('./data/yelp2019/item_index_corpus_emb.pkl', \"wb\") as fOut:\n",
    "#         pickle.dump({'sentences': item_index_sent, 'embeddings': item_index_contrust}, fOut)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "user_index_contrust[5].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(1):\n",
    "    if i%500==0:\n",
    "        print(i)\n",
    "    temp_u=[]\n",
    "    for j in range(len(user_aspect[i])):\n",
    "        sents_u = user_aspect[i]\n",
    "#         print(user_aspect[0][0])\n",
    "        temp_u.append(user_aspect[i][j])\n",
    "    tttt=model.encode(user_aspect[i])\n",
    "tttt.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "temp_u"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tttt[4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#对用户所有的评论，分句后取平均值\n",
    "# user_rev_emb=[]\n",
    "# for i in range(len(user_revs)):\n",
    "#     if i%500==0:\n",
    "#         print(i)\n",
    "#     li_u=[]\n",
    "#     for j in range(len(user_revs[i])):\n",
    "#         li_u.append(user_revs[i][j])\n",
    "#     tttt=model.encode(li_u)\n",
    "#     tttt=torch.tensor(tttt)\n",
    "#     tttt=tttt.sum(dim=0)/len(user_revs[i])\n",
    "#     user_rev_emb.append(tttt)\n",
    "# user_rev_emb = torch.tensor([item.detach().numpy() for item in user_rev_emb])\n",
    "# user_rev_emb=user_rev_emb.numpy()\n",
    "# user_rev_emb.shape\n",
    "# torch.save(user_rev_emb,'./data/yelp2019/user_avg_rev_emb.pt')\n",
    "#对item所有的评论，分句后取平均值\n",
    "item_rev_emb=[]\n",
    "for i in range(len(item_aspect)):\n",
    "    if i%500==0:\n",
    "        print(i)\n",
    "    li_u=[]\n",
    "    for j in range(len(item_aspect[i])):\n",
    "        li_u.append(item_aspect[i][j])\n",
    "    tttt=model.encode(li_u)\n",
    "    tttt=torch.tensor(tttt)\n",
    "    tttt=tttt.sum(dim=0)/len(item_aspect[i])\n",
    "    item_rev_emb.append(tttt)\n",
    "item_rev_emb = torch.tensor([item.detach().numpy() for item in item_rev_emb])\n",
    "item_rev_emb=item_rev_emb.numpy()\n",
    "item_rev_emb.shape\n",
    "torch.save(item_rev_emb,'./data/TripAdvisor/item_avg_aspect_emb.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df=pd.read_json('./data/train-data/user_glabos_retrive.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "item_aspect[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reviews=list(train_df['review'])\n",
    "len(reviews)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reviews[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#建立global索引\n",
    "temp_u = []\n",
    "for i in range(len(reviews)):\n",
    "    if i%50000==0:\n",
    "        print(i)\n",
    "#     sents_u = sent_tokenize(reviews[i])\n",
    "    temp_u.append(reviews[i])\n",
    "print(len(temp_u))\n",
    "re_emb=model.encode(temp_u,show_progress_bar=True)\n",
    "re_emb.shape\n",
    "with open('./data/train-data/yelp_each_sent_emb.pkl', \"wb\") as fOut:\n",
    "        pickle.dump({'sentences': temp_u, 'embeddings': re_emb}, fOut)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "user_revs=pd.read_pickle('./data/train-data/user_reviews.pkl')\n",
    "item_revs=pd.read_pickle('./data/train-data/item_reviews.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(item_revs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "user_rev_emb=torch.load('./data/train-data/index/user_avg_rev_emb.pt')\n",
    "item_rev_emb=torch.load('./data/train-data/index/item_avg_rev_emb.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "user_rev_emb=torch.load('./data/train-data/user_glabos_retrive.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "user_rev_emb.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "corpus_emb=pd.read_pickle('./data/train-data/yelp_each_sent_emb.pkl')\n",
    "temp_u = corpus_emb['sentences']\n",
    "re_emb = corpus_emb['embeddings']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(re_emb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#全局检索\n",
    "print('begin')\n",
    "quantizer = faiss.IndexFlatL2(384)  # the other index\n",
    "index = faiss.IndexIVFFlat(quantizer,384, 1000, faiss.METRIC_L2)\n",
    "index.train(re_emb)\n",
    "index.add(re_emb)\n",
    "assert index.is_trained\n",
    "print(\"ok\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('开始user')\n",
    "D_u,I_u = index.search(user_rev_emb,3)\n",
    "user_retrive=[]\n",
    "for i in range(len(user_revs)):\n",
    "    if i%500==0:\n",
    "        print(i)\n",
    "    temp=''\n",
    "    for j in range(3):\n",
    "        temp=temp_u[I_u[i][j]]+temp\n",
    "    user_temp =model.encode(temp)\n",
    "    user_retrive.append(user_temp)\n",
    "user_retrive=torch.tensor(user_retrive)\n",
    "user_retrive.shape\n",
    "torch.save(user_retrive,'./data/train-data/user_glabos_retrive.pt')\n",
    "D_i,I_i = index.search(item_rev_emb,3)\n",
    "print('开始item')\n",
    "item_retrive=[]\n",
    "for i in range(len(item_revs)):\n",
    "    if i%500==0:\n",
    "        print(i)\n",
    "    temp=''\n",
    "    for j in range(3):\n",
    "        temp=temp_u[I_i[i][j]]+temp\n",
    "    item_temp =model.encode(temp)\n",
    "    item_retrive.append(item_temp)\n",
    "item_retrive=torch.tensor(item_retrive)\n",
    "item_retrive.shape\n",
    "torch.save(item_retrive,'./data/train-data/item_glabos_retrive.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "user_toitem=torch.load('./data/TripAdvisor/user_to_item_list/user_toitem.pt')\n",
    "# item_revs=pd.read_pickle('./data/TripAdvisor/user_to_item_list/item_reviews.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#检索查询\n",
    "user_rev_By_itemretrive={}\n",
    "temp_review=[]\n",
    "for i in range(len(user_revs)):\n",
    "    if i %500==0:\n",
    "        print(i)\n",
    "    temp_By_itemretrive={}\n",
    "    quantizer = faiss.IndexFlatL2(384)  # the other index\n",
    "    index = faiss.IndexIVFFlat(quantizer,384,1, faiss.METRIC_L2)\n",
    "    index.train(user_index_contrust[i])\n",
    "    index.add(user_index_contrust[i])\n",
    "    D_u,I_u = index.search(item_rev_emb[user_toitem[i]],2)\n",
    "#     print(I_u)\n",
    "    for j in range(len(user_toitem[i])):\n",
    "        temp=''\n",
    "        for t in range(2):\n",
    "            temp=user_index_sent[i][I_u[j][t]]+temp\n",
    "#             temp_emb=model.encode(temp)\n",
    "        temp_review.append(temp)\n",
    "        temp_By_itemretrive[user_toitem[i][j]]=temp\n",
    "#         temp_By_itemretrive[user_toitem[i][j]]=user_index_contrust[i][I_u[j][0]]\n",
    "    user_rev_By_itemretrive[i]=temp_By_itemretrive"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#aspect查询\n",
    "user_rev_By_itemretrive={}\n",
    "temp_review=[]\n",
    "for i in range(len(user_aspect)):\n",
    "    if i %500==0:\n",
    "        print(i)\n",
    "    temp_By_itemretrive={}\n",
    "    quantizer = faiss.IndexFlatL2(384)  # the other index\n",
    "    index = faiss.IndexIVFFlat(quantizer,384,1, faiss.METRIC_L2)\n",
    "    index.train(user_index_contrust[i])\n",
    "    index.add(user_index_contrust[i])\n",
    "    D_u,I_u = index.search(item_rev_emb[user_toitem[i]],2)\n",
    "#     print(I_u)\n",
    "    for j in range(len(user_toitem[i])):\n",
    "        temp=[]\n",
    "        for t in range(2):\n",
    "            temp.append(user_index_sent[i][I_u[j][t]])\n",
    "#             temp_emb=model.encode(temp)\n",
    "#         temp_review.append(temp)\n",
    "        temp_By_itemretrive[user_toitem[i][j]]=temp\n",
    "#         temp_By_itemretrive[user_toitem[i][j]]=user_index_contrust[i][I_u[j][0]]\n",
    "    user_rev_By_itemretrive[i]=temp_By_itemretrive"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('./data/TripAdvisor/aspect_retrive_top2.pkl', \"wb\") as fOut:\n",
    "        pickle.dump(user_rev_By_itemretrive, fOut)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(temp_review)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "top2=pd.read_pickle('./data/TripAdvisor/aspect_retrive_top2.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "top2[8115]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "temppp=torch.rand(4,16)\n",
    "temppp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "temppp[:2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tema=torch.rand(1,16)\n",
    "tema"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "src = torch.cat([temppp[:2],tema,temppp[2:]], 0)\n",
    "src"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(model.max_seq_length)\n",
    "model.max_seq_length=512\n",
    "print(model.max_seq_length)\n",
    "temp_review_emb=model.encode(temp_review,show_progress_bar=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "user_rev_By_itemretrive={}\n",
    "count=0\n",
    "for i in range(len(user_revs)):\n",
    "    temp_By_itemretrive={}\n",
    "    for j in range(len(user_toitem[i])):\n",
    "        temp_By_itemretrive[user_toitem[i][j]]=temp_review_emb[count]\n",
    "        count=count+1\n",
    "    user_rev_By_itemretrive[i]=temp_By_itemretrive\n",
    "print(count)\n",
    "torch.save(user_rev_By_itemretrive,'./data/cells/user_revemb_By_item_retrive.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(item_touser[6])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "item_rev_By_userretrive={}\n",
    "temp_review=[]\n",
    "for i in range(len(item_revs)):\n",
    "    if i %200==0:\n",
    "        print(i)\n",
    "    temp_By_userretrive={}\n",
    "    quantizer = faiss.IndexFlatL2(384)  # the other index\n",
    "    index = faiss.IndexIVFFlat(quantizer,384, 1, faiss.METRIC_L2)\n",
    "    index.train(item_index_contrust[i])\n",
    "    index.add(item_index_contrust[i])\n",
    "    D_u,I_u = index.search(user_rev_emb[item_touser[i]],3)\n",
    "    for j in range(len(item_touser[i])):\n",
    "        temp=''\n",
    "        for t in range(3):\n",
    "            temp=item_index_sent[i][I_u[j][t]]+temp\n",
    "#             temp_emb=model.encode(temp)\n",
    "        temp_review.append(temp)\n",
    "        temp_By_userretrive[item_touser[i][j]]=temp\n",
    "#         temp_By_userretrive[item_touser[i][j]]=item_index_contrust[i][I_u[j][0]]#支取一条查询\n",
    "    item_rev_By_userretrive[i]=temp_By_userretrive"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(model.max_seq_length)\n",
    "model.max_seq_length=512\n",
    "print(model.max_seq_length)\n",
    "temp_review_emb=model.encode(temp_review,show_progress_bar=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "item_rev_By_userretrive={}\n",
    "count=0\n",
    "for i in range(len(item_revs)):\n",
    "    temp_By_itemretrive={}\n",
    "    for j in range(len(item_touser[i])):\n",
    "        temp_By_itemretrive[item_touser[i][j]]=temp_review_emb[count]\n",
    "        count=count+1\n",
    "    item_rev_By_userretrive[i]=temp_By_itemretrive\n",
    "print(count)\n",
    "torch.save(item_rev_By_userretrive,'./data/yelp2019/item_revemb_By_user_retrive.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "item_rev_By_userretrive[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
